{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c53409e4",
      "metadata": {
        "id": "c53409e4"
      },
      "outputs": [],
      "source": [
        "pip install hpelm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7132592d",
      "metadata": {
        "id": "7132592d"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd4d589",
      "metadata": {
        "id": "ebd4d589"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a48ac8e",
      "metadata": {
        "id": "8a48ac8e"
      },
      "outputs": [],
      "source": [
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bcfccc4",
      "metadata": {
        "id": "9bcfccc4"
      },
      "outputs": [],
      "source": [
        "pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee35047",
      "metadata": {
        "id": "4ee35047"
      },
      "outputs": [],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51349f75",
      "metadata": {
        "id": "51349f75"
      },
      "outputs": [],
      "source": [
        "pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29addebe",
      "metadata": {
        "id": "29addebe"
      },
      "outputs": [],
      "source": [
        "pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1dccd9e",
      "metadata": {
        "id": "b1dccd9e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow.keras as keras\n",
        "os.environ[\"KERAS_BACKEND\"] = 'tensorflow'\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, Input, Conv2D, MaxPool2D, MaxPooling2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from keras.models import Model, load_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from hpelm import ELM\n",
        "import plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d158c1db",
      "metadata": {
        "id": "d158c1db"
      },
      "outputs": [],
      "source": [
        "np.random.seed(22)\n",
        "\n",
        "import plotly.figure_factory as ff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0862e376",
      "metadata": {
        "id": "0862e376"
      },
      "outputs": [],
      "source": [
        "def load_organic(norm_path):\n",
        "        norm_files = np.array(os.listdir(norm_path))\n",
        "        norm_labels = np.array(['organic']*len(norm_files))\n",
        "\n",
        "        norm_images = []\n",
        "        for image in tqdm(norm_files):\n",
        "            image = cv2.imread(os.path.join(norm_path,image))\n",
        "            image = cv2.resize(image, dsize=(224,224))\n",
        "            if(image is not None):\n",
        "                norm_images.append(image)\n",
        "\n",
        "        norm_images = np.array(norm_images)\n",
        "\n",
        "        return norm_images, norm_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60fd68f8",
      "metadata": {
        "id": "60fd68f8"
      },
      "outputs": [],
      "source": [
        "def load_recylable(pneu_path):\n",
        "        pneu_files = np.array(os.listdir(pneu_path))\n",
        "        pneu_labels = np.array(['recyclable']*len(pneu_files))\n",
        "\n",
        "        pneu_images = []\n",
        "        for image in tqdm(pneu_files):\n",
        "            image = cv2.imread(os.path.join(pneu_path,image))\n",
        "            image = cv2.resize(image, dsize=(224,224))\n",
        "            if(image is not None):\n",
        "                 pneu_images.append(image)\n",
        "\n",
        "        pneu_images = np.array(pneu_images)\n",
        "\n",
        "        return pneu_images, pneu_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26bf2ef0",
      "metadata": {
        "id": "26bf2ef0"
      },
      "outputs": [],
      "source": [
        "#training data\n",
        "dataset_em = \"Waste_data/DATASET/TRAIN/O\"\n",
        "dataset_oc = \"Waste_data/DATASET/TRAIN/R\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daef7850",
      "metadata": {
        "id": "daef7850"
      },
      "outputs": [],
      "source": [
        "#testing data\n",
        "dataset_em_test = \"Waste_data/DATASET/TEST/O\"\n",
        "dataset_oc_test = \"Waste_data/DATASET/TEST/R\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73afd945",
      "metadata": {
        "id": "73afd945"
      },
      "outputs": [],
      "source": [
        "norm_images, norm_labels = load_organic(dataset_em)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f5edad",
      "metadata": {
        "id": "50f5edad"
      },
      "outputs": [],
      "source": [
        "pneu_images, pneu_labels = load_recyclable(dataset_oc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b6fa646",
      "metadata": {
        "id": "2b6fa646"
      },
      "outputs": [],
      "source": [
        "# Put all train images to X_train\n",
        "X_train = np.append(norm_images, pneu_images, axis=0)\n",
        "\n",
        "# Put all train labels to y_train\n",
        "y_train = np.append(norm_labels, pneu_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af596bb2",
      "metadata": {
        "id": "af596bb2"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e59d9e",
      "metadata": {
        "id": "40e59d9e"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=7, nrows=2, figsize=(16, 4))\n",
        "\n",
        "indices = np.random.choice(len(X_train), 14)\n",
        "counter = 0\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(7):\n",
        "        axes[i,j].set_title(y_train[indices[counter]])\n",
        "        axes[i,j].imshow(X_train[indices[counter]], cmap='gray')\n",
        "        axes[i,j].get_xaxis().set_visible(False)\n",
        "        axes[i,j].get_yaxis().set_visible(False)\n",
        "        counter += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b444d958",
      "metadata": {
        "id": "b444d958"
      },
      "outputs": [],
      "source": [
        "# Do the exact same thing as what we have done on train data\n",
        "norm_images_test, norm_labels_test = load_organic(dataset_em_test)\n",
        "pneu_images_test, pneu_labels_test = load_recyclable(dataset_oc_test)\n",
        "X_test = np.append(norm_images_test, pneu_images_test, axis=0)\n",
        "y_test = np.append(norm_labels_test, pneu_labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95e6b522",
      "metadata": {
        "id": "95e6b522"
      },
      "outputs": [],
      "source": [
        "# Save the loaded images to pickle file for future use\n",
        " # Use this to save variables\n",
        "with open('waste_data.pickle', 'wb') as f:\n",
        "    pickle.dump((X_train, X_test, y_train, y_test), f)\n",
        "\n",
        "    # Here's how to load it\n",
        "    # Use this to load variables\n",
        "with open('waste_data.pickle', 'rb') as f:\n",
        "    (X_train, X_test, y_train, y_test) = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6185b0",
      "metadata": {
        "id": "0e6185b0"
      },
      "outputs": [],
      "source": [
        "# Create new axis on all y data\n",
        "y_train = y_train[:, np.newaxis]\n",
        "y_test = y_test[:, np.newaxis]\n",
        "\n",
        "    # Initialize OneHotEncoder object\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "\n",
        "    # Convert all labels to one-hot\n",
        "y_train_one_hot = one_hot_encoder.fit_transform(y_train)\n",
        "y_test_one_hot = one_hot_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "    # reshape for conv layer\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c21acd",
      "metadata": {
        "id": "77c21acd"
      },
      "outputs": [],
      "source": [
        "# increase the number of data used for training by creating more samples with some sort of randomness on each of them\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 10,\n",
        "    zoom_range = 0.1,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88ebb13",
      "metadata": {
        "id": "c88ebb13"
      },
      "outputs": [],
      "source": [
        "datagen.fit(X_train)\n",
        "train_gen = datagen.flow(X_train, y_train_one_hot, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b93b59",
      "metadata": {
        "id": "84b93b59"
      },
      "outputs": [],
      "source": [
        "width = X_train.shape[1]\n",
        "height = X_train.shape[2]\n",
        "channel = 3\n",
        "NUM_CLASS = 2\n",
        "\n",
        "hidden_size = 120\n",
        "\n",
        "# Encoding target\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.fit_transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48afb30",
      "metadata": {
        "id": "d48afb30"
      },
      "outputs": [],
      "source": [
        "print(y_train_enc.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c21bc10",
      "metadata": {
        "id": "7c21bc10"
      },
      "outputs": [],
      "source": [
        "from keras.applications import vgg16\n",
        "imported_model=tf.keras.applications.VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e47a4d63",
      "metadata": {
        "id": "e47a4d63"
      },
      "outputs": [],
      "source": [
        "dnn_model = Sequential()\n",
        "dnn_model.add(imported_model)\n",
        "dnn_model.add(Flatten())\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(256, activation='relu'))\n",
        "dnn_model.add(Dropout(0.2))\n",
        "dnn_model.add(Dense(2, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "700b4fa0",
      "metadata": {
        "id": "700b4fa0"
      },
      "outputs": [],
      "source": [
        "dnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e16ed7",
      "metadata": {
        "id": "77e16ed7"
      },
      "outputs": [],
      "source": [
        "dnn_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}